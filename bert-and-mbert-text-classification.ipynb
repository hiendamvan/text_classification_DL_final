{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10191730,"sourceType":"datasetVersion","datasetId":6297039}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import AdamW\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:05:13.861292Z","iopub.execute_input":"2024-12-14T03:05:13.861644Z","iopub.status.idle":"2024-12-14T03:05:19.208229Z","shell.execute_reply.started":"2024-12-14T03:05:13.861582Z","shell.execute_reply":"2024-12-14T03:05:19.207550Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/text-classification/preprocessed_data.csv')\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:05:19.210280Z","iopub.execute_input":"2024-12-14T03:05:19.211269Z","iopub.status.idle":"2024-12-14T03:05:19.771365Z","shell.execute_reply.started":"2024-12-14T03:05:19.211224Z","shell.execute_reply":"2024-12-14T03:05:19.770560Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                          Paragraph  Topic\n0           0  khoảng thiếu_niên ngụ xã thượng quận thị_xã ki...      0\n1           1  hai xe đối_đầu tạo tiếng_động mạnh ba người đi...      0\n2           2  camera hành_trình của ôtô đi trên đoạn đường đ...      0\n3           3          camera hành_trình ghi lại vụ tai_nạn sáng      0\n4           4  đoạn đường xảy ra tai_nạn không có dải_phân_cá...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Paragraph</th>\n      <th>Topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>khoảng thiếu_niên ngụ xã thượng quận thị_xã ki...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>hai xe đối_đầu tạo tiếng_động mạnh ba người đi...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>camera hành_trình của ôtô đi trên đoạn đường đ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>camera hành_trình ghi lại vụ tai_nạn sáng</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>đoạn đường xảy ra tai_nạn không có dải_phân_cá...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"#filter only need column: Paragraph and Topic\ndata = data[['Paragraph', 'Topic']]\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:05:19.772540Z","iopub.execute_input":"2024-12-14T03:05:19.772861Z","iopub.status.idle":"2024-12-14T03:05:19.786022Z","shell.execute_reply.started":"2024-12-14T03:05:19.772835Z","shell.execute_reply":"2024-12-14T03:05:19.785107Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                           Paragraph  Topic\n0  khoảng thiếu_niên ngụ xã thượng quận thị_xã ki...      0\n1  hai xe đối_đầu tạo tiếng_động mạnh ba người đi...      0\n2  camera hành_trình của ôtô đi trên đoạn đường đ...      0\n3          camera hành_trình ghi lại vụ tai_nạn sáng      0\n4  đoạn đường xảy ra tai_nạn không có dải_phân_cá...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Paragraph</th>\n      <th>Topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>khoảng thiếu_niên ngụ xã thượng quận thị_xã ki...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hai xe đối_đầu tạo tiếng_động mạnh ba người đi...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>camera hành_trình của ôtô đi trên đoạn đường đ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>camera hành_trình ghi lại vụ tai_nạn sáng</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>đoạn đường xảy ra tai_nạn không có dải_phân_cá...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# creat train, val, test dataset\ntrain = data.sample(frac=0.8, random_state=200)\ntest = data.drop(train.index)\nval = test.sample(frac=0.5, random_state=200)\ntest = test.drop(val.index)\ntrain.shape, val.shape, test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:05:19.786991Z","iopub.execute_input":"2024-12-14T03:05:19.787266Z","iopub.status.idle":"2024-12-14T03:05:19.807514Z","shell.execute_reply.started":"2024-12-14T03:05:19.787242Z","shell.execute_reply":"2024-12-14T03:05:19.806644Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"((24000, 2), (3000, 2), (3000, 2))"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(train)\nval_dataset = Dataset.from_pandas(val)\ntest_dataset = Dataset.from_pandas(test)\ntrain_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:05:19.808376Z","iopub.execute_input":"2024-12-14T03:05:19.808627Z","iopub.status.idle":"2024-12-14T03:05:19.956012Z","shell.execute_reply.started":"2024-12-14T03:05:19.808583Z","shell.execute_reply":"2024-12-14T03:05:19.955139Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Paragraph', 'Topic', '__index_level_0__'],\n    num_rows: 24000\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Using BERT","metadata":{}},{"cell_type":"code","source":"#load pretrained model\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\ntokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:05:19.957068Z","iopub.execute_input":"2024-12-14T03:05:19.957415Z","iopub.status.idle":"2024-12-14T03:05:21.322435Z","shell.execute_reply.started":"2024-12-14T03:05:19.957378Z","shell.execute_reply":"2024-12-14T03:05:21.321551Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aaaf7d5be574204b199f8b2087d553a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09a6739c26f54e9ba4dc66ac4f812e96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16578de8a31343bfb4150647aa13333e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db1a6ad7a9542c1a72ec5e3dae3dcb2"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def encode(docs):\n    '''\n    This function takes list of texts and returns input_ids and attention_mask of texts\n    '''\n    encoded_dict = tokenizer.batch_encode_plus(docs, add_special_tokens=True, max_length=128, padding='max_length',\n                            return_attention_mask=True, truncation=True, return_tensors='pt')\n    input_ids = encoded_dict['input_ids']\n    attention_masks = encoded_dict['attention_mask']\n    return input_ids, attention_masks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:05:21.324338Z","iopub.execute_input":"2024-12-14T03:05:21.324642Z","iopub.status.idle":"2024-12-14T03:05:21.329277Z","shell.execute_reply.started":"2024-12-14T03:05:21.324616Z","shell.execute_reply":"2024-12-14T03:05:21.328460Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# convert data to vector\ntrain_input_ids, train_attention_masks = encode(train_dataset['Paragraph'])\nval_input_ids, val_attention_masks = encode(val_dataset['Paragraph'])\ntest_input_ids, test_attention_masks = encode(test_dataset['Paragraph'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:05:21.333156Z","iopub.execute_input":"2024-12-14T03:05:21.333441Z","iopub.status.idle":"2024-12-14T03:05:27.591899Z","shell.execute_reply.started":"2024-12-14T03:05:21.333417Z","shell.execute_reply":"2024-12-14T03:05:27.590859Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_y = torch.LongTensor(train_dataset['Topic'])\nval_y = torch.LongTensor(val_dataset['Topic'])\ntest_y = torch.LongTensor(test_dataset['Topic'])\ntrain_y.size(), val_y.size(), test_y.size()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:05:27.593478Z","iopub.execute_input":"2024-12-14T03:05:27.593840Z","iopub.status.idle":"2024-12-14T03:05:27.614504Z","shell.execute_reply.started":"2024-12-14T03:05:27.593799Z","shell.execute_reply":"2024-12-14T03:05:27.613761Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(torch.Size([24000]), torch.Size([3000]), torch.Size([3000]))"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# create dataset\ntrain_dataset = torch.utils.data.TensorDataset(train_input_ids, train_attention_masks, train_y)\nval_dataset = torch.utils.data.TensorDataset(val_input_ids, val_attention_masks, val_y)\ntest_dataset = torch.utils.data.TensorDataset(test_input_ids, test_attention_masks, test_y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:05:27.615650Z","iopub.execute_input":"2024-12-14T03:05:27.616187Z","iopub.status.idle":"2024-12-14T03:05:27.628260Z","shell.execute_reply.started":"2024-12-14T03:05:27.616161Z","shell.execute_reply":"2024-12-14T03:05:27.627582Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# create dataloader\nBATCH_SIZE = 64\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:12:03.784164Z","iopub.execute_input":"2024-12-13T15:12:03.784511Z","iopub.status.idle":"2024-12-13T15:12:03.789200Z","shell.execute_reply.started":"2024-12-13T15:12:03.784480Z","shell.execute_reply":"2024-12-13T15:12:03.788374Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from transformers import BertForSequenceClassification\nN_labels = len(data['Topic'].unique())\nPRETRAINED_LM = \"bert-base-uncased\"\nmodel = BertForSequenceClassification.from_pretrained(PRETRAINED_LM,\n                                                      num_labels=N_labels,\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:12:13.880724Z","iopub.execute_input":"2024-12-13T15:12:13.881057Z","iopub.status.idle":"2024-12-13T15:12:28.283197Z","shell.execute_reply.started":"2024-12-13T15:12:13.881030Z","shell.execute_reply":"2024-12-13T15:12:28.282373Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fd5e4eb15f845fc891aab1d0615489c"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:06:18.696666Z","iopub.execute_input":"2024-12-14T03:06:18.697466Z","iopub.status.idle":"2024-12-14T03:06:18.778290Z","shell.execute_reply.started":"2024-12-14T03:06:18.697419Z","shell.execute_reply":"2024-12-14T03:06:18.777299Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:12:39.980780Z","iopub.execute_input":"2024-12-13T15:12:39.981131Z","iopub.status.idle":"2024-12-13T15:12:40.324948Z","shell.execute_reply.started":"2024-12-13T15:12:39.981102Z","shell.execute_reply":"2024-12-13T15:12:40.324075Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=15, bias=True)\n)"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=1e-5)\ncriterion = torch.nn.CrossEntropyLoss()\nn_epochs = 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:23:42.444272Z","iopub.execute_input":"2024-12-13T15:23:42.444581Z","iopub.status.idle":"2024-12-13T15:23:42.451959Z","shell.execute_reply.started":"2024-12-13T15:23:42.444555Z","shell.execute_reply":"2024-12-13T15:23:42.451239Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"for epoch in range(n_epochs):  # Số epoch\n    model.train()  # Chuyển mô hình sang chế độ huấn luyện\n    total_loss = 0\n\n    for batch in train_loader:\n        # Chuyển dữ liệu sang GPU\n        input_ids = batch[0].to(device)\n        attention_mask = batch[1].to(device)\n        labels = batch[2].to(device)\n\n        # Forward pass\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        logits = outputs.logits\n\n        # Backward pass và tối ưu hóa\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch + 1}, Loss: {avg_loss}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:25:57.430498Z","iopub.execute_input":"2024-12-13T15:25:57.431322Z","iopub.status.idle":"2024-12-13T15:47:45.911087Z","shell.execute_reply.started":"2024-12-13T15:25:57.431289Z","shell.execute_reply":"2024-12-13T15:47:45.910167Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 2.320306606610616\nEpoch 2, Loss: 1.6629444481531779\nEpoch 3, Loss: 1.269620681444804\nEpoch 4, Loss: 1.0196111399332681\nEpoch 5, Loss: 0.8457004788716634\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"    # Đánh giá trên tập validation\n    model.eval()  # Chuyển mô hình sang chế độ đánh giá\n    val_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[0].to(device)\n            attention_mask = batch[1].to(device)\n            labels = batch[2].to(device)\n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            loss = criterion(logits, labels)\n\n            val_loss += loss.item()\n            predictions = torch.argmax(logits, dim=-1)\n            correct += (predictions == labels).sum().item()\n            total += labels.size(0)\n\n    avg_val_loss = val_loss / len(val_loader)\n    accuracy = correct / total\n    print(f\"Validation Loss: {avg_val_loss}, Accuracy: {accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:50:00.322254Z","iopub.execute_input":"2024-12-13T15:50:00.322616Z","iopub.status.idle":"2024-12-13T15:50:10.479633Z","shell.execute_reply.started":"2024-12-13T15:50:00.322575Z","shell.execute_reply":"2024-12-13T15:50:10.478671Z"}},"outputs":[{"name":"stdout","text":"Validation Loss: 0.9456534943682082, Accuracy: 0.7266666666666667\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# tuning batchsize, and more epochs ","metadata":{}},{"cell_type":"code","source":"# create dataloader\nBATCH_SIZE = 128\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:05:42.938829Z","iopub.execute_input":"2024-12-14T03:05:42.939169Z","iopub.status.idle":"2024-12-14T03:05:42.944268Z","shell.execute_reply.started":"2024-12-14T03:05:42.939140Z","shell.execute_reply":"2024-12-14T03:05:42.943427Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from transformers import BertForSequenceClassification\nN_labels = len(data['Topic'].unique())\nPRETRAINED_LM = \"bert-base-uncased\"\nmodel = BertForSequenceClassification.from_pretrained(PRETRAINED_LM,\n                                                      num_labels=N_labels,\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)\noptimizer = AdamW(model.parameters(), lr=1e-5)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:05:50.793069Z","iopub.execute_input":"2024-12-14T03:05:50.793860Z","iopub.status.idle":"2024-12-14T03:06:05.232674Z","shell.execute_reply.started":"2024-12-14T03:05:50.793828Z","shell.execute_reply":"2024-12-14T03:06:05.231555Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa84a4d823c2487daf8054abfa931507"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:06:27.016200Z","iopub.execute_input":"2024-12-14T03:06:27.017103Z","iopub.status.idle":"2024-12-14T03:06:27.354022Z","shell.execute_reply.started":"2024-12-14T03:06:27.017069Z","shell.execute_reply":"2024-12-14T03:06:27.353115Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=15, bias=True)\n)"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"n_epochs = 20\nfor epoch in range(n_epochs):  # Số epoch\n    model.train()  # Chuyển mô hình sang chế độ huấn luyện\n    total_loss = 0\n\n    for batch in train_loader:\n        # Chuyển dữ liệu sang GPU\n        input_ids = batch[0].to(device)\n        attention_mask = batch[1].to(device)\n        labels = batch[2].to(device)\n\n        # Forward pass\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        logits = outputs.logits\n\n        # Backward pass và tối ưu hóa\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch + 1}, Loss: {avg_loss}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T03:06:32.829143Z","iopub.execute_input":"2024-12-14T03:06:32.830003Z","iopub.status.idle":"2024-12-14T04:31:01.047649Z","shell.execute_reply.started":"2024-12-14T03:06:32.829967Z","shell.execute_reply":"2024-12-14T04:31:01.046868Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 2.4330859964198255\nEpoch 2, Loss: 1.8230474451754957\nEpoch 3, Loss: 1.4249215164083116\nEpoch 4, Loss: 1.1820216359610254\nEpoch 5, Loss: 1.0016568902325123\nEpoch 6, Loss: 0.8607771922933295\nEpoch 7, Loss: 0.7622305316493866\nEpoch 8, Loss: 0.6738500862996629\nEpoch 9, Loss: 0.6045275712583927\nEpoch 10, Loss: 0.533783347999796\nEpoch 11, Loss: 0.47744172145711616\nEpoch 12, Loss: 0.41828553957190917\nEpoch 13, Loss: 0.38181055091479993\nEpoch 14, Loss: 0.34057610814875744\nEpoch 15, Loss: 0.29706993057055675\nEpoch 16, Loss: 0.2687494138929438\nEpoch 17, Loss: 0.22667152830894957\nEpoch 18, Loss: 0.20637939141151754\nEpoch 19, Loss: 0.17866829323007705\nEpoch 20, Loss: 0.1630858269103981\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"55","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    # Đánh giá trên tập validation\n    model.eval()  # Chuyển mô hình sang chế độ đánh giá\n    val_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[0].to(device)\n            attention_mask = batch[1].to(device)\n            labels = batch[2].to(device)\n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            loss = criterion(logits, labels)\n\n            val_loss += loss.item()\n            predictions = torch.argmax(logits, dim=-1)\n            correct += (predictions == labels).sum().item()\n            total += labels.size(0)\n\n    avg_val_loss = val_loss / len(val_loader)\n    accuracy = correct / total\n    print(f\"Validation Loss: {avg_val_loss}, Accuracy: {accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T04:31:57.901483Z","iopub.execute_input":"2024-12-14T04:31:57.901820Z","iopub.status.idle":"2024-12-14T04:32:08.179999Z","shell.execute_reply.started":"2024-12-14T04:31:57.901794Z","shell.execute_reply":"2024-12-14T04:32:08.179098Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Validation Loss: 0.8689365101357301, Accuracy: 0.792\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"    # Đánh giá trên tập validation\n    model.eval()  # Chuyển mô hình sang chế độ đánh giá\n    val_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for batch in test_loader:\n            input_ids = batch[0].to(device)\n            attention_mask = batch[1].to(device)\n            labels = batch[2].to(device)\n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            loss = criterion(logits, labels)\n\n            val_loss += loss.item()\n            predictions = torch.argmax(logits, dim=-1)\n            correct += (predictions == labels).sum().item()\n            total += labels.size(0)\n\n    avg_val_loss = val_loss / len(val_loader)\n    accuracy = correct / total\n    print(f\"Test Loss: {avg_val_loss}, Accuracy: {accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T04:36:25.531519Z","iopub.execute_input":"2024-12-14T04:36:25.532468Z","iopub.status.idle":"2024-12-14T04:36:35.714066Z","shell.execute_reply.started":"2024-12-14T04:36:25.532421Z","shell.execute_reply":"2024-12-14T04:36:35.713133Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 0.9282514819254478, Accuracy: 0.7786666666666666\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Using mBERT","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# Tải tokenizer và model\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=15)  # num_labels là số nhãn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T04:48:05.662995Z","iopub.execute_input":"2024-12-14T04:48:05.663681Z","iopub.status.idle":"2024-12-14T04:48:06.169266Z","shell.execute_reply.started":"2024-12-14T04:48:05.663652Z","shell.execute_reply":"2024-12-14T04:48:06.168649Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# convert data to vector\ntrain_dataset = Dataset.from_pandas(train)\nval_dataset = Dataset.from_pandas(val)\ntest_dataset = Dataset.from_pandas(test)\n\ntrain_input_ids, train_attention_masks = encode(train_dataset['Paragraph'])\nval_input_ids, val_attention_masks = encode(val_dataset['Paragraph'])\ntest_input_ids, test_attention_masks = encode(test_dataset['Paragraph'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T04:46:19.234321Z","iopub.execute_input":"2024-12-14T04:46:19.235141Z","iopub.status.idle":"2024-12-14T04:46:24.446324Z","shell.execute_reply.started":"2024-12-14T04:46:19.235109Z","shell.execute_reply":"2024-12-14T04:46:24.445362Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"train_y = torch.LongTensor(train_dataset['Topic'])\nval_y = torch.LongTensor(val_dataset['Topic'])\ntest_y = torch.LongTensor(test_dataset['Topic'])\ntrain_y.size(), val_y.size(), test_y.size()\n# create dataset\ntrain_dataset = torch.utils.data.TensorDataset(train_input_ids, train_attention_masks, train_y)\nval_dataset = torch.utils.data.TensorDataset(val_input_ids, val_attention_masks, val_y)\ntest_dataset = torch.utils.data.TensorDataset(test_input_ids, test_attention_masks, test_y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T04:47:02.601987Z","iopub.execute_input":"2024-12-14T04:47:02.602575Z","iopub.status.idle":"2024-12-14T04:47:02.620311Z","shell.execute_reply.started":"2024-12-14T04:47:02.602545Z","shell.execute_reply":"2024-12-14T04:47:02.619537Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# create dataloader\nBATCH_SIZE = 128\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T04:47:39.805313Z","iopub.execute_input":"2024-12-14T04:47:39.806105Z","iopub.status.idle":"2024-12-14T04:47:39.810827Z","shell.execute_reply.started":"2024-12-14T04:47:39.806069Z","shell.execute_reply":"2024-12-14T04:47:39.810013Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T04:48:10.672594Z","iopub.execute_input":"2024-12-14T04:48:10.672954Z","iopub.status.idle":"2024-12-14T04:48:10.967630Z","shell.execute_reply.started":"2024-12-14T04:48:10.672925Z","shell.execute_reply":"2024-12-14T04:48:10.966831Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=15, bias=True)\n)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=5e-5)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T04:50:40.584008Z","iopub.execute_input":"2024-12-14T04:50:40.584688Z","iopub.status.idle":"2024-12-14T04:50:40.591925Z","shell.execute_reply.started":"2024-12-14T04:50:40.584657Z","shell.execute_reply":"2024-12-14T04:50:40.591045Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"n_epochs = 20\nfor epoch in range(n_epochs):  # Số epoch\n    model.train()  # Chuyển mô hình sang chế độ huấn luyện\n    total_loss = 0\n\n    for batch in train_loader:\n        # Chuyển dữ liệu sang GPU\n        input_ids = batch[0].to(device)\n        attention_mask = batch[1].to(device)\n        labels = batch[2].to(device)\n\n        # Forward pass\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        logits = outputs.logits\n\n        # Backward pass và tối ưu hóa\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch + 1}, Loss: {avg_loss}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T04:50:42.859328Z","iopub.execute_input":"2024-12-14T04:50:42.860012Z","iopub.status.idle":"2024-12-14T06:15:50.782204Z","shell.execute_reply.started":"2024-12-14T04:50:42.859980Z","shell.execute_reply":"2024-12-14T06:15:50.781133Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 1.1428306857322126\nEpoch 2, Loss: 0.5760411108110813\nEpoch 3, Loss: 0.37477342340540376\nEpoch 4, Loss: 0.2512518341871018\nEpoch 5, Loss: 0.17411563745600747\nEpoch 6, Loss: 0.13183454782801104\nEpoch 7, Loss: 0.10441979716353594\nEpoch 8, Loss: 0.08839132499564042\nEpoch 9, Loss: 0.07521265920529023\nEpoch 10, Loss: 0.05962347530541902\nEpoch 11, Loss: 0.056969885609082956\nEpoch 12, Loss: 0.05384847771455633\nEpoch 13, Loss: 0.043884292475264916\nEpoch 14, Loss: 0.05642719416472902\nEpoch 15, Loss: 0.04390608184559746\nEpoch 16, Loss: 0.04016202698991773\nEpoch 17, Loss: 0.036933601529218575\nEpoch 18, Loss: 0.04711126502073231\nEpoch 19, Loss: 0.03852256714859284\nEpoch 20, Loss: 0.030706665839038867\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"    # Đánh giá trên tập validation\n    model.eval()  # Chuyển mô hình sang chế độ đánh giá\n    val_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for batch in test_loader:\n            input_ids = batch[0].to(device)\n            attention_mask = batch[1].to(device)\n            labels = batch[2].to(device)\n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            loss = criterion(logits, labels)\n\n            val_loss += loss.item()\n            predictions = torch.argmax(logits, dim=-1)\n            correct += (predictions == labels).sum().item()\n            total += labels.size(0)\n\n    avg_val_loss = val_loss / len(val_loader)\n    accuracy = correct / total\n    print(f\"Test Loss: {avg_val_loss}, Accuracy: {accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T06:19:40.808719Z","iopub.execute_input":"2024-12-14T06:19:40.809062Z","iopub.status.idle":"2024-12-14T06:19:50.991971Z","shell.execute_reply.started":"2024-12-14T06:19:40.809034Z","shell.execute_reply":"2024-12-14T06:19:50.991091Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 0.6529186942304174, Accuracy: 0.8663333333333333\n","output_type":"stream"}],"execution_count":35}]}